<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Preprocessing Steps</title>
    <style>
        body {
            font-family: 'Arial', sans-serif;
            line-height: 1.6;
            margin: 20px;
            background-color: #f4f4f4;
            color: #333;
        }
        h1 {
            color: #0056b3;
            border-bottom: 2px solid #0056b3;
            padding-bottom: 10px;
        }
        ol {
            margin-top: 20px;
            padding-left: 20px;
        }
        li {
            margin-bottom: 10px;
        }
        strong {
            color: #0056b3;
        }
    </style>
</head>
<body>
    <h1>Preprocessing Steps</h1>
    <p>Here's a step-by-step breakdown of the preprocessing techniques applied to the review texts in our sentiment analysis:</p>
    <ol>
        <li>
            <strong>Lowercasing:</strong> We convert all text to lowercase to ensure consistency and uniformity. This helps the model treat words like "Good" and "good" as the same.
        </li>
        <li>
            <strong>Tokenization:</strong> The text is broken down into individual words or tokens. This step involves splitting the text by spaces and punctuation, enabling the model to analyze each word separately.
        </li>
        <li>
            <strong>Stopword Removal:</strong> Common words such as "the," "is," "and," which carry little to no meaning for sentiment analysis, are removed. This reduces noise in the data.
        </li>
        <li>
            <strong>Stemming/Lemmatization:</strong> Words are reduced to their root form. Stemming uses a heuristic process that chops off the ends of words, while lemmatization involves reducing words to their dictionary form, which is more context-aware.
        </li>
        <li>
          <strong>Punctuation Removal:</strong> All punctuation is removed so that the model doesn't see them as tokens.
      </li>
    </ol>
</body>
</html>